{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d565f56f",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-02T18:42:46.515Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import unidecode \n",
    "from bs4 import BeautifulSoup \n",
    "# from wordcloud import WordCloud\n",
    "import re\n",
    "import emoji\n",
    "import nltk\n",
    "from autocorrect import Speller \n",
    "import numpy as np\n",
    "import re \n",
    "import time \n",
    "import nltk\n",
    "from emoticon_fix import emoticon_fix\n",
    "from autocorrect import Speller \n",
    "import spacy\n",
    "import nltk.corpus\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,confusion_matrix,roc_curve,classification_report\n",
    "# from scikitplot.metrics import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9156159b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T17:46:48.417501Z",
     "start_time": "2023-03-07T17:46:48.259438Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Video Number</th>\n",
       "      <th>Title</th>\n",
       "      <th>Date Published</th>\n",
       "      <th>Views</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Auther</th>\n",
       "      <th>Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>The Learning Resource That Helped People Crack...</td>\n",
       "      <td>2022-07-21</td>\n",
       "      <td>4809</td>\n",
       "      <td>180</td>\n",
       "      <td>Relax_user</td>\n",
       "      <td>Hi Mr.Patel, I am thinking about doing a maste...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>The Learning Resource That Helped People Crack...</td>\n",
       "      <td>2022-07-21</td>\n",
       "      <td>4809</td>\n",
       "      <td>180</td>\n",
       "      <td>Harsh Mehta</td>\n",
       "      <td>Pls come up with data analyst or data engineer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>The Learning Resource That Helped People Crack...</td>\n",
       "      <td>2022-07-21</td>\n",
       "      <td>4809</td>\n",
       "      <td>180</td>\n",
       "      <td>Nikhil Sachdeva</td>\n",
       "      <td>I am learning the full stack web app developme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>The Learning Resource That Helped People Crack...</td>\n",
       "      <td>2022-07-21</td>\n",
       "      <td>4809</td>\n",
       "      <td>180</td>\n",
       "      <td>Ajinkya</td>\n",
       "      <td>Hello, Did you teach data analysis using Jupyt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>The Learning Resource That Helped People Crack...</td>\n",
       "      <td>2022-07-21</td>\n",
       "      <td>4809</td>\n",
       "      <td>180</td>\n",
       "      <td>Mohammed Shabaaz</td>\n",
       "      <td>Please come up with SQL course please?Eagerly ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Video Number                                              Title  \\\n",
       "0             1  The Learning Resource That Helped People Crack...   \n",
       "1             1  The Learning Resource That Helped People Crack...   \n",
       "2             1  The Learning Resource That Helped People Crack...   \n",
       "3             1  The Learning Resource That Helped People Crack...   \n",
       "4             1  The Learning Resource That Helped People Crack...   \n",
       "\n",
       "  Date Published  Views  Likes            Auther  \\\n",
       "0     2022-07-21   4809    180        Relax_user   \n",
       "1     2022-07-21   4809    180       Harsh Mehta   \n",
       "2     2022-07-21   4809    180   Nikhil Sachdeva   \n",
       "3     2022-07-21   4809    180           Ajinkya   \n",
       "4     2022-07-21   4809    180  Mohammed Shabaaz   \n",
       "\n",
       "                                             Comment  \n",
       "0  Hi Mr.Patel, I am thinking about doing a maste...  \n",
       "1  Pls come up with data analyst or data engineer...  \n",
       "2  I am learning the full stack web app developme...  \n",
       "3  Hello, Did you teach data analysis using Jupyt...  \n",
       "4  Please come up with SQL course please?Eagerly ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_df=pd.read_csv('Youtube_comments_codebasics.csv')\n",
    "comments_df.drop('Unnamed: 0', inplace=True, axis=1)\n",
    "comments_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c04ef4fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T17:46:48.949408Z",
     "start_time": "2023-03-07T17:46:48.932883Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18726, 7)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2768cbd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T17:46:49.961559Z",
     "start_time": "2023-03-07T17:46:49.946917Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Video Number', 'Title', 'Date Published', 'Views', 'Likes', 'Auther',\n",
       "       'Comment'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad83faa3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T17:46:50.715546Z",
     "start_time": "2023-03-07T17:46:50.689858Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Video Number</th>\n",
       "      <th>Views</th>\n",
       "      <th>Likes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>18726.000000</td>\n",
       "      <td>1.872600e+04</td>\n",
       "      <td>18726.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>283.104080</td>\n",
       "      <td>1.944550e+05</td>\n",
       "      <td>5464.186639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>132.009849</td>\n",
       "      <td>2.447171e+05</td>\n",
       "      <td>8908.334056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.104000e+03</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>195.000000</td>\n",
       "      <td>3.303500e+04</td>\n",
       "      <td>729.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>270.000000</td>\n",
       "      <td>8.093600e+04</td>\n",
       "      <td>1834.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>411.000000</td>\n",
       "      <td>2.500060e+05</td>\n",
       "      <td>5068.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>527.000000</td>\n",
       "      <td>1.043729e+06</td>\n",
       "      <td>37329.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Video Number         Views         Likes\n",
       "count  18726.000000  1.872600e+04  18726.000000\n",
       "mean     283.104080  1.944550e+05   5464.186639\n",
       "std      132.009849  2.447171e+05   8908.334056\n",
       "min        1.000000  1.104000e+03      1.000000\n",
       "25%      195.000000  3.303500e+04    729.000000\n",
       "50%      270.000000  8.093600e+04   1834.000000\n",
       "75%      411.000000  2.500060e+05   5068.000000\n",
       "max      527.000000  1.043729e+06  37329.000000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "372ea52a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T17:46:51.551166Z",
     "start_time": "2023-03-07T17:46:51.529332Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18726 entries, 0 to 18725\n",
      "Data columns (total 7 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   Video Number    18726 non-null  int64 \n",
      " 1   Title           18726 non-null  object\n",
      " 2   Date Published  18726 non-null  object\n",
      " 3   Views           18726 non-null  int64 \n",
      " 4   Likes           18726 non-null  int64 \n",
      " 5   Auther          17558 non-null  object\n",
      " 6   Comment         18145 non-null  object\n",
      "dtypes: int64(3), object(4)\n",
      "memory usage: 1.0+ MB\n"
     ]
    }
   ],
   "source": [
    "comments_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3fca4bba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T17:46:52.192518Z",
     "start_time": "2023-03-07T17:46:52.176576Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Video Number         0\n",
       "Title                0\n",
       "Date Published       0\n",
       "Views                0\n",
       "Likes                0\n",
       "Auther            1168\n",
       "Comment            581\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1676fce9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T17:46:52.764509Z",
     "start_time": "2023-03-07T17:46:52.753760Z"
    }
   },
   "outputs": [],
   "source": [
    "comments_df.dropna(subset=['Comment'], inplace=True, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "daecdfa2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T17:46:55.472954Z",
     "start_time": "2023-03-07T17:46:55.448531Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Video Number        0\n",
       "Title               0\n",
       "Date Published      0\n",
       "Views               0\n",
       "Likes               0\n",
       "Auther            642\n",
       "Comment             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc01d1c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T17:46:56.950264Z",
     "start_time": "2023-03-07T17:46:56.936516Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18145, 7)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed908d32",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T17:46:57.699254Z",
     "start_time": "2023-03-07T17:46:57.473522Z"
    }
   },
   "outputs": [],
   "source": [
    "comments_df.to_csv(\"comments_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "13b0f7ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T17:46:59.388661Z",
     "start_time": "2023-03-07T17:46:59.375546Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Video Number</th>\n",
       "      <th>Title</th>\n",
       "      <th>Date Published</th>\n",
       "      <th>Views</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Auther</th>\n",
       "      <th>Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>The Learning Resource That Helped People Crack...</td>\n",
       "      <td>2022-07-21</td>\n",
       "      <td>4809</td>\n",
       "      <td>180</td>\n",
       "      <td>Relax_user</td>\n",
       "      <td>Hi Mr.Patel, I am thinking about doing a maste...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>The Learning Resource That Helped People Crack...</td>\n",
       "      <td>2022-07-21</td>\n",
       "      <td>4809</td>\n",
       "      <td>180</td>\n",
       "      <td>Harsh Mehta</td>\n",
       "      <td>Pls come up with data analyst or data engineer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>The Learning Resource That Helped People Crack...</td>\n",
       "      <td>2022-07-21</td>\n",
       "      <td>4809</td>\n",
       "      <td>180</td>\n",
       "      <td>Nikhil Sachdeva</td>\n",
       "      <td>I am learning the full stack web app developme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>The Learning Resource That Helped People Crack...</td>\n",
       "      <td>2022-07-21</td>\n",
       "      <td>4809</td>\n",
       "      <td>180</td>\n",
       "      <td>Ajinkya</td>\n",
       "      <td>Hello, Did you teach data analysis using Jupyt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>The Learning Resource That Helped People Crack...</td>\n",
       "      <td>2022-07-21</td>\n",
       "      <td>4809</td>\n",
       "      <td>180</td>\n",
       "      <td>Mohammed Shabaaz</td>\n",
       "      <td>Please come up with SQL course please?Eagerly ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Video Number                                              Title  \\\n",
       "0             1  The Learning Resource That Helped People Crack...   \n",
       "1             1  The Learning Resource That Helped People Crack...   \n",
       "2             1  The Learning Resource That Helped People Crack...   \n",
       "3             1  The Learning Resource That Helped People Crack...   \n",
       "4             1  The Learning Resource That Helped People Crack...   \n",
       "\n",
       "  Date Published  Views  Likes            Auther  \\\n",
       "0     2022-07-21   4809    180        Relax_user   \n",
       "1     2022-07-21   4809    180       Harsh Mehta   \n",
       "2     2022-07-21   4809    180   Nikhil Sachdeva   \n",
       "3     2022-07-21   4809    180           Ajinkya   \n",
       "4     2022-07-21   4809    180  Mohammed Shabaaz   \n",
       "\n",
       "                                             Comment  \n",
       "0  Hi Mr.Patel, I am thinking about doing a maste...  \n",
       "1  Pls come up with data analyst or data engineer...  \n",
       "2  I am learning the full stack web app developme...  \n",
       "3  Hello, Did you teach data analysis using Jupyt...  \n",
       "4  Please come up with SQL course please?Eagerly ...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b10c44",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636c2b65",
   "metadata": {},
   "source": [
    "<b>Text Cleaning  and Preproccressing</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ca586c",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bea0c05b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T17:47:03.484824Z",
     "start_time": "2023-03-07T17:47:03.472148Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Check https://codebasics.io/?utm_source=pin-comment&utm_medium=yt&utm_campaign=pin-comment&utm_id=youtube for my video courses (that are based on project based effective and intuitive learning)'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_df.iloc[139]['Comment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9aaf964f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T17:47:04.178982Z",
     "start_time": "2023-03-07T17:47:04.158557Z"
    }
   },
   "outputs": [],
   "source": [
    "def remove_links(text):\n",
    "    # Removing all the occurrences of links that starts with https\n",
    "    remove_https = re.sub(r'http\\S+', '', text)\n",
    "    # Remove all the occurrences of text that ends with .com\n",
    "    remove_com = re.sub(r\"\\ [A-Za-z]*\\.com\", \" \", remove_https)\n",
    "    return remove_com\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b920eec2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T17:47:06.532282Z",
     "start_time": "2023-03-07T17:47:06.447783Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Check  for my video courses (that are based on project based effective and intuitive learning)'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_df['Clean_comment'] = comments_df['Comment'].apply(remove_links)\n",
    "comments_df.iloc[139]['Clean_comment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "af181530",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T17:47:08.403779Z",
     "start_time": "2023-03-07T17:47:08.382673Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Video Number</th>\n",
       "      <th>Title</th>\n",
       "      <th>Date Published</th>\n",
       "      <th>Views</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Auther</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Clean_comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>The Learning Resource That Helped People Crack...</td>\n",
       "      <td>2022-07-21</td>\n",
       "      <td>4809</td>\n",
       "      <td>180</td>\n",
       "      <td>Relax_user</td>\n",
       "      <td>Hi Mr.Patel, I am thinking about doing a maste...</td>\n",
       "      <td>Hi Mr.Patel, I am thinking about doing a maste...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>The Learning Resource That Helped People Crack...</td>\n",
       "      <td>2022-07-21</td>\n",
       "      <td>4809</td>\n",
       "      <td>180</td>\n",
       "      <td>Harsh Mehta</td>\n",
       "      <td>Pls come up with data analyst or data engineer...</td>\n",
       "      <td>Pls come up with data analyst or data engineer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>The Learning Resource That Helped People Crack...</td>\n",
       "      <td>2022-07-21</td>\n",
       "      <td>4809</td>\n",
       "      <td>180</td>\n",
       "      <td>Nikhil Sachdeva</td>\n",
       "      <td>I am learning the full stack web app developme...</td>\n",
       "      <td>I am learning the full stack web app developme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>The Learning Resource That Helped People Crack...</td>\n",
       "      <td>2022-07-21</td>\n",
       "      <td>4809</td>\n",
       "      <td>180</td>\n",
       "      <td>Ajinkya</td>\n",
       "      <td>Hello, Did you teach data analysis using Jupyt...</td>\n",
       "      <td>Hello, Did you teach data analysis using Jupyt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>The Learning Resource That Helped People Crack...</td>\n",
       "      <td>2022-07-21</td>\n",
       "      <td>4809</td>\n",
       "      <td>180</td>\n",
       "      <td>Mohammed Shabaaz</td>\n",
       "      <td>Please come up with SQL course please?Eagerly ...</td>\n",
       "      <td>Please come up with SQL course please?Eagerly ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Video Number                                              Title  \\\n",
       "0             1  The Learning Resource That Helped People Crack...   \n",
       "1             1  The Learning Resource That Helped People Crack...   \n",
       "2             1  The Learning Resource That Helped People Crack...   \n",
       "3             1  The Learning Resource That Helped People Crack...   \n",
       "4             1  The Learning Resource That Helped People Crack...   \n",
       "\n",
       "  Date Published  Views  Likes            Auther  \\\n",
       "0     2022-07-21   4809    180        Relax_user   \n",
       "1     2022-07-21   4809    180       Harsh Mehta   \n",
       "2     2022-07-21   4809    180   Nikhil Sachdeva   \n",
       "3     2022-07-21   4809    180           Ajinkya   \n",
       "4     2022-07-21   4809    180  Mohammed Shabaaz   \n",
       "\n",
       "                                             Comment  \\\n",
       "0  Hi Mr.Patel, I am thinking about doing a maste...   \n",
       "1  Pls come up with data analyst or data engineer...   \n",
       "2  I am learning the full stack web app developme...   \n",
       "3  Hello, Did you teach data analysis using Jupyt...   \n",
       "4  Please come up with SQL course please?Eagerly ...   \n",
       "\n",
       "                                       Clean_comment  \n",
       "0  Hi Mr.Patel, I am thinking about doing a maste...  \n",
       "1  Pls come up with data analyst or data engineer...  \n",
       "2  I am learning the full stack web app developme...  \n",
       "3  Hello, Did you teach data analysis using Jupyt...  \n",
       "4  Please come up with SQL course please?Eagerly ...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3230f7a5",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fec569bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T17:47:12.453806Z",
     "start_time": "2023-03-07T17:47:12.441605Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Sir I'm fresher and i haven't done any project untill and naukri app is asking for add project( 8%) how can i remove it and i can make it to 100%\\nPlz help me\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_df.iloc[4272]['Clean_comment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7a438b81",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T17:47:16.058813Z",
     "start_time": "2023-03-07T17:47:16.041785Z"
    }
   },
   "outputs": [],
   "source": [
    "CONTRACTION_MAP = {\n",
    "\"ain't\": \"is not\",\n",
    "\"aren't\": \"are not\",\n",
    "\"can't\": \"cannot\",\n",
    "\"can't've\": \"cannot have\",\n",
    "\"'cause\": \"because\",\n",
    "\"could've\": \"could have\",\n",
    "\"couldn't\": \"could not\",\n",
    "\"couldn't've\": \"could not have\",\n",
    "\"didn't\": \"did not\",\n",
    "\"doesn't\": \"does not\",\n",
    "\"don't\": \"do not\",\n",
    "\"hadn't\": \"had not\",\n",
    "\"hadn't've\": \"had not have\",\n",
    "\"hasn't\": \"has not\",\n",
    "\"haven't\": \"have not\",\n",
    "\"he'd\": \"he would\",\n",
    "\"he'd've\": \"he would have\",\n",
    "\"he'll\": \"he will\",\n",
    "\"he'll've\": \"he he will have\",\n",
    "\"he's\": \"he is\",\n",
    "\"how'd\": \"how did\",\n",
    "\"how'd'y\": \"how do you\",\n",
    "\"how'll\": \"how will\",\n",
    "\"how's\": \"how is\",\n",
    "\"i'd\": \"i would\",\n",
    "\"i'd've\": \"i would have\",\n",
    "\"i'll\": \"i will\",\n",
    "\"i'll've\": \"i will have\",\n",
    "\"i'm\": \"i am\",\n",
    "\"i've\": \"i have\",\n",
    "\"isn't\": \"is not\",\n",
    "\"it'd\": \"it would\",\n",
    "\"it'd've\": \"it would have\",\n",
    "\"it'll\": \"it will\",\n",
    "\"it'll've\": \"it will have\",\n",
    "\"it's\": \"it is\",\n",
    "\"let's\": \"let us\",\n",
    "\"ma'am\": \"madam\",\n",
    "\"mayn't\": \"may not\",\n",
    "\"might've\": \"might have\",\n",
    "\"mightn't\": \"might not\",\n",
    "\"mightn't've\": \"might not have\",\n",
    "\"must've\": \"must have\",\n",
    "\"mustn't\": \"must not\",\n",
    "\"mustn't've\": \"must not have\",\n",
    "\"needn't\": \"need not\",\n",
    "\"needn't've\": \"need not have\",\n",
    "\"o'clock\": \"of the clock\",\n",
    "\"oughtn't\": \"ought not\",\n",
    "\"oughtn't've\": \"ought not have\",\n",
    "\"shan't\": \"shall not\",\n",
    "\"sha'n't\": \"shall not\",\n",
    "\"shan't've\": \"shall not have\",\n",
    "\"she'd\": \"she would\",\n",
    "\"she'd've\": \"she would have\",\n",
    "\"she'll\": \"she will\",\n",
    "\"she'll've\": \"she will have\",\n",
    "\"she's\": \"she is\",\n",
    "\"should've\": \"should have\",\n",
    "\"shouldn't\": \"should not\",\n",
    "\"shouldn't've\": \"should not have\",\n",
    "\"so've\": \"so have\",\n",
    "\"so's\": \"so as\",\n",
    "\"that'd\": \"that would\",\n",
    "\"that'd've\": \"that would have\",\n",
    "\"that's\": \"that is\",\n",
    "\"there'd\": \"there would\",\n",
    "\"there'd've\": \"there would have\",\n",
    "\"there's\": \"there is\",\n",
    "\"they'd\": \"they would\",\n",
    "\"they'd've\": \"they would have\",\n",
    "\"they'll\": \"they will\",\n",
    "\"they'll've\": \"they will have\",\n",
    "\"they're\": \"they are\",\n",
    "\"they've\": \"they have\",\n",
    "\"to've\": \"to have\",\n",
    "\"wasn't\": \"was not\",\n",
    "\"we'd\": \"we would\",\n",
    "\"we'd've\": \"we would have\",\n",
    "\"we'll\": \"we will\",\n",
    "\"we'll've\": \"we will have\",\n",
    "\"we're\": \"we are\",\n",
    "\"we've\": \"we have\",\n",
    "\"weren't\": \"were not\",\n",
    "\"what'll\": \"what will\",\n",
    "\"what'll've\": \"what will have\",\n",
    "\"what're\": \"what are\",\n",
    "\"what's\": \"what is\",\n",
    "\"what've\": \"what have\",\n",
    "\"when's\": \"when is\",\n",
    "\"when've\": \"when have\",\n",
    "\"where'd\": \"where did\",\n",
    "\"where's\": \"where is\",\n",
    "\"where've\": \"where have\",\n",
    "\"who'll\": \"who will\",\n",
    "\"who'll've\": \"who will have\",\n",
    "\"who's\": \"who is\",\n",
    "\"who've\": \"who have\",\n",
    "\"why's\": \"why is\",\n",
    "\"why've\": \"why have\",\n",
    "\"will've\": \"will have\",\n",
    "\"won't\": \"will not\",\n",
    "\"won't've\": \"will not have\",\n",
    "\"would've\": \"would have\",\n",
    "\"wouldn't\": \"would not\",\n",
    "\"wouldn't've\": \"would not have\",\n",
    "\"y'all\": \"you all\",\n",
    "\"y'all'd\": \"you all would\",\n",
    "\"y'all'd've\": \"you all would have\",\n",
    "\"y'all're\": \"you all are\",\n",
    "\"y'all've\": \"you all have\",\n",
    "\"you'd\": \"you would\",\n",
    "\"you'd've\": \"you would have\",\n",
    "\"you'll\": \"you will\",\n",
    "\"you'll've\": \"you will have\",\n",
    "\"you're\": \"you are\",\n",
    "\"you've\": \"you have\",\n",
    "}\n",
    "# The code for expanding contraction words\n",
    "def expand_contractions(text, contraction_mapping =  CONTRACTION_MAP):\n",
    "    # Tokenizing text into tokens.\n",
    "    list_Of_tokens = text.split(' ')\n",
    "    \n",
    "    # Check whether Word is in list_Of_tokens or not.\n",
    "    for Word in list_Of_tokens: \n",
    "        # Check whether found word is in dictionary \"Contraction Map\" or not as a key. \n",
    "         if Word in CONTRACTION_MAP: \n",
    "                # If Word is present in both dictionary & list_Of_tokens, replace that word with the key value.\n",
    "                list_Of_tokens = [item.replace(Word, CONTRACTION_MAP[Word]) for item in list_Of_tokens]\n",
    "                \n",
    "    # Converting list of tokens to String.\n",
    "    String_Of_tokens = ' '.join(str(e) for e in list_Of_tokens) \n",
    "    return String_Of_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d6541e3b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T17:47:16.615713Z",
     "start_time": "2023-03-07T17:47:16.470904Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Sir I'm fresher and i have not done any project untill and naukri app is asking for add project( 8%) how can i remove it and i can make it to 100%\\nPlz help me\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_df['Clean_comment'] = comments_df['Comment'].apply(expand_contractions)\n",
    "comments_df.iloc[4272]['Clean_comment']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972e9ac4",
   "metadata": {},
   "source": [
    "**Dealing with Emoticon i.e :-)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "713d653f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T17:47:17.435719Z",
     "start_time": "2023-03-07T17:47:17.422344Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exercise Completed without your Solution. Thanks :-)\n"
     ]
    }
   ],
   "source": [
    "print(comments_df.iloc[202]['Clean_comment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "30610f94",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T17:47:21.648543Z",
     "start_time": "2023-03-07T17:47:17.888554Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exercise Completed without your Solution . Thanks Smile\n"
     ]
    }
   ],
   "source": [
    "comments_df['Clean_comment'] = comments_df['Comment'].apply(emoticon_fix.emoticon_fix)\n",
    "print(comments_df.iloc[202]['Clean_comment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b90959",
   "metadata": {},
   "source": [
    "**Dealing with Emoji i.e :-)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f76aced0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T17:47:22.344605Z",
     "start_time": "2023-03-07T17:47:21.650979Z"
    }
   },
   "outputs": [],
   "source": [
    "comments_df['Clean_comment'] = comments_df['Clean_comment'].apply(emoji.demojize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "198c6491",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T17:47:23.347301Z",
     "start_time": "2023-03-07T17:47:23.249545Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check  for my video courses ( that are based on project based effective and intuitive learning )\n",
      "Sir I'm fresher and i haven't done any project untill and naukri app is asking for add project ( 8 % ) how can i remove it and i can make it to 100 % Plz help me\n"
     ]
    }
   ],
   "source": [
    "comments_df['Clean_comment'] = comments_df['Clean_comment'].apply(remove_links)\n",
    "print(comments_df.iloc[139]['Clean_comment'])\n",
    "print(comments_df.iloc[4272]['Clean_comment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e891f37d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T17:47:24.118476Z",
     "start_time": "2023-03-07T17:47:24.107045Z"
    }
   },
   "outputs": [],
   "source": [
    "def clean_comments(text):\n",
    "    \"takes text in raw format and returns clean text with only words and letters. \"\n",
    "    \n",
    "    text = re.sub(r\"[0-9]+\", \"\", text)\n",
    "    text = text.lower()   # Lower case\n",
    "    \n",
    "    text = re.sub(r\"_\", \" \", text)\n",
    "    text = re.sub(r\"[0-9]+\", \"\", text)\n",
    "    text = re.sub(r\"(@\\[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?\", \"\", text)\n",
    "    text = re.sub(r'[-\"?$+:&%!.(),@>]', \"\", text)\n",
    "    text = re.sub(r\"\\/\", \" \", text)\n",
    "    text = re.sub(r\"\\n\", \" \", text)\n",
    "    text = re.sub(r\"'s\", \"\", text)\n",
    "    \n",
    "    text = text.replace('@', '')\n",
    "    text = re.sub(r\"[^a-zA-Z0-9:$-,%.?!]+\", ' ', text) \n",
    "    text = re.sub(r\"(@\\[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?\", \"\", text)\n",
    "    text = text.replace('\\\\n', ' ').replace('\\n', ' ').replace('\\t',' ').replace('\\\\', ' ').replace('. com', '.com')\n",
    "    \n",
    "    # remove_whitespace\n",
    "    pattern = re.compile(r'\\s+') \n",
    "    Without_whitespace = re.sub(pattern, ' ', text)\n",
    "    # There are some instances where there is no space after '?' & ')', \n",
    "    # So I am replacing these with one space so that It will not consider two words as one token.\n",
    "    text = Without_whitespace.replace('?', ' ? ').replace(')', ') ')\n",
    "    return text\n",
    "    \n",
    "    text = unidecode.unidecode(text)\n",
    "    \n",
    "    text = text.strip()\n",
    "    \n",
    "    return text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7396e562",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T17:47:25.844626Z",
     "start_time": "2023-03-07T17:47:24.722617Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check for my video courses that are based on project based effective and intuitive learning \n",
      "exercise completed without your solution thanks smile\n",
      "sir im fresher and i havent done any project untill and naukri app is asking for add project how can i remove it and i can make it to plz help me\n"
     ]
    }
   ],
   "source": [
    "comments_df['Clean_comment'] = comments_df['Clean_comment'].apply(clean_comments)\n",
    "print(comments_df.iloc[139]['Clean_comment'])\n",
    "print(comments_df.iloc[202]['Clean_comment'])\n",
    "print(comments_df.iloc[4272]['Clean_comment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a524b993",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T17:47:26.463502Z",
     "start_time": "2023-03-07T17:47:26.447034Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'thank uuuu so muchhh sirrr '"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_df.iloc[4291]['Clean_comment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cb5a9e44",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T17:47:28.713762Z",
     "start_time": "2023-03-07T17:47:28.706007Z"
    }
   },
   "outputs": [],
   "source": [
    "# Code for removing repeated characters and punctuations\n",
    "\n",
    "def reducing_incorrect_character_repeatation(text):\n",
    "    \n",
    "    # Pattern matching for all case alphabets\n",
    "    Pattern_alpha = re.compile(r\"([A-Za-z])\\1{1,}\", re.DOTALL)\n",
    "    \n",
    "    # Limiting all the  repeatation to two characters.\n",
    "    Formatted_text = Pattern_alpha.sub(r\"\\1\\1\", text) \n",
    "    \n",
    "    # Pattern matching for all the punctuations that can occur\n",
    "    Pattern_Punct = re.compile(r'([.,/#!$%^&*?;:{}=_`~()+-])\\1{1,}')\n",
    "    \n",
    "    # Limiting punctuations in previously formatted string to only one.\n",
    "    Combined_Formatted = Pattern_Punct.sub(r'\\\\euler', Formatted_text)\n",
    "    \n",
    "    # The below statement is replacing repeatation of spaces that occur more than two times with that of one occurrence.\n",
    "    Final_Formatted = re.sub(' {2,}',' ', Combined_Formatted)\n",
    "    return Final_Formatted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "21b04f12",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T17:47:29.839536Z",
     "start_time": "2023-03-07T17:47:29.504139Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'thank uu so muchh sirr '"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_df['Clean_comment'] = comments_df['Clean_comment'].apply(reducing_incorrect_character_repeatation)\n",
    "comments_df.iloc[4291]['Clean_comment']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8301c653",
   "metadata": {},
   "source": [
    "### The various text preprocessing steps are:\n",
    "\n",
    "#### 1:-Stop words removal\n",
    "#### 2:-Tokenization\n",
    "#### 3:-Stemming\n",
    "#### 4:-Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "251e283c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T17:47:32.156958Z",
     "start_time": "2023-03-07T17:47:31.931831Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('i', 11178),\n",
       " ('the', 9850),\n",
       " ('to', 9794),\n",
       " ('you', 9516),\n",
       " ('and', 7476),\n",
       " ('for', 7176),\n",
       " ('a', 6882),\n",
       " ('in', 6065),\n",
       " ('is', 5268),\n",
       " ('of', 4609)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the first 10 most frequent words\n",
    "from collections import Counter\n",
    "cnt = Counter()\n",
    "for text in comments_df['Clean_comment'].values:\n",
    "    for word in text.split():\n",
    "        cnt[word] += 1\n",
    "        \n",
    "cnt.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d05a99ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T17:47:32.580915Z",
     "start_time": "2023-03-07T17:47:32.570737Z"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9daedc68",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T17:47:42.548778Z",
     "start_time": "2023-03-07T17:47:42.536814Z"
    }
   },
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    \n",
    "    new_text = []\n",
    "    for i in text.split(' '):\n",
    "        \n",
    "        if i not in stop_words:\n",
    "            str(new_text.append(i))\n",
    "            new_text.append(' ')\n",
    "        else:\n",
    "            pass\n",
    "            \n",
    "    text = ''.join(new_text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae433a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-03T18:44:14.090987Z",
     "start_time": "2022-08-03T18:44:14.061222Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3746e82e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T17:47:44.994662Z",
     "start_time": "2023-03-07T17:47:44.120925Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        hi mrpatel thinking masters data analytics how...\n",
       "1        pls come data analyst data engineer bootcamp e...\n",
       "2        learning full stack web app development dsa js...\n",
       "3        hello teach data analysis using jupyter notebo...\n",
       "4        please come sql course please eagerly waiting ...\n",
       "                               ...                        \n",
       "18195                                        mobile phone \n",
       "18196                                 chromebook download \n",
       "18197                             please make video scipy \n",
       "18198          unable install python windows machine help \n",
       "18199                           get error x cantu install \n",
       "Name: Clean_comment, Length: 18145, dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_df['Clean_comment'] = comments_df['Clean_comment'].apply(remove_stopwords)\n",
    "comments_df['Clean_comment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c87de2ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T17:47:45.098757Z",
     "start_time": "2023-03-07T17:47:44.997593Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('sir', 4577),\n",
       " ('data', 3455),\n",
       " ('thank', 3075),\n",
       " ('video', 3044),\n",
       " ('thanks', 2394),\n",
       " ('please', 2093),\n",
       " ('great', 1747),\n",
       " ('much', 1730),\n",
       " ('videos', 1591),\n",
       " ('learning', 1411)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the first 10 most frequent words\n",
    "from collections import Counter\n",
    "cnt = Counter()\n",
    "for text in comments_df['Clean_comment'].values:\n",
    "    for word in text.split():\n",
    "        cnt[word] += 1\n",
    "        \n",
    "cnt.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "72886417",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T17:47:45.625823Z",
     "start_time": "2023-03-07T17:47:45.603315Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Video Number</th>\n",
       "      <th>Title</th>\n",
       "      <th>Date Published</th>\n",
       "      <th>Views</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Auther</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Clean_comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>The Learning Resource That Helped People Crack...</td>\n",
       "      <td>2022-07-21</td>\n",
       "      <td>4809</td>\n",
       "      <td>180</td>\n",
       "      <td>Relax_user</td>\n",
       "      <td>Hi Mr.Patel, I am thinking about doing a maste...</td>\n",
       "      <td>hi mrpatel thinking masters data analytics how...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>The Learning Resource That Helped People Crack...</td>\n",
       "      <td>2022-07-21</td>\n",
       "      <td>4809</td>\n",
       "      <td>180</td>\n",
       "      <td>Harsh Mehta</td>\n",
       "      <td>Pls come up with data analyst or data engineer...</td>\n",
       "      <td>pls come data analyst data engineer bootcamp e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>The Learning Resource That Helped People Crack...</td>\n",
       "      <td>2022-07-21</td>\n",
       "      <td>4809</td>\n",
       "      <td>180</td>\n",
       "      <td>Nikhil Sachdeva</td>\n",
       "      <td>I am learning the full stack web app developme...</td>\n",
       "      <td>learning full stack web app development dsa js...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>The Learning Resource That Helped People Crack...</td>\n",
       "      <td>2022-07-21</td>\n",
       "      <td>4809</td>\n",
       "      <td>180</td>\n",
       "      <td>Ajinkya</td>\n",
       "      <td>Hello, Did you teach data analysis using Jupyt...</td>\n",
       "      <td>hello teach data analysis using jupyter notebo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>The Learning Resource That Helped People Crack...</td>\n",
       "      <td>2022-07-21</td>\n",
       "      <td>4809</td>\n",
       "      <td>180</td>\n",
       "      <td>Mohammed Shabaaz</td>\n",
       "      <td>Please come up with SQL course please?Eagerly ...</td>\n",
       "      <td>please come sql course please eagerly waiting ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Video Number                                              Title  \\\n",
       "0             1  The Learning Resource That Helped People Crack...   \n",
       "1             1  The Learning Resource That Helped People Crack...   \n",
       "2             1  The Learning Resource That Helped People Crack...   \n",
       "3             1  The Learning Resource That Helped People Crack...   \n",
       "4             1  The Learning Resource That Helped People Crack...   \n",
       "\n",
       "  Date Published  Views  Likes            Auther  \\\n",
       "0     2022-07-21   4809    180        Relax_user   \n",
       "1     2022-07-21   4809    180       Harsh Mehta   \n",
       "2     2022-07-21   4809    180   Nikhil Sachdeva   \n",
       "3     2022-07-21   4809    180           Ajinkya   \n",
       "4     2022-07-21   4809    180  Mohammed Shabaaz   \n",
       "\n",
       "                                             Comment  \\\n",
       "0  Hi Mr.Patel, I am thinking about doing a maste...   \n",
       "1  Pls come up with data analyst or data engineer...   \n",
       "2  I am learning the full stack web app developme...   \n",
       "3  Hello, Did you teach data analysis using Jupyt...   \n",
       "4  Please come up with SQL course please?Eagerly ...   \n",
       "\n",
       "                                       Clean_comment  \n",
       "0  hi mrpatel thinking masters data analytics how...  \n",
       "1  pls come data analyst data engineer bootcamp e...  \n",
       "2  learning full stack web app development dsa js...  \n",
       "3  hello teach data analysis using jupyter notebo...  \n",
       "4  please come sql course please eagerly waiting ...  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4e87a6b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T17:47:54.161225Z",
     "start_time": "2023-03-07T17:47:54.086813Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\harsh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\harsh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import pos_tag\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4dff3ca",
   "metadata": {},
   "source": [
    "<b>Tokenization</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6d46500d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T17:47:57.584938Z",
     "start_time": "2023-03-07T17:47:55.388526Z"
    }
   },
   "outputs": [],
   "source": [
    "comments_df['Tokenized'] = comments_df['Clean_comment'].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1779bcb1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T17:47:57.602818Z",
     "start_time": "2023-03-07T17:47:57.588553Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [hi, mrpatel, thinking, masters, data, analyti...\n",
       "1    [pls, come, data, analyst, data, engineer, boo...\n",
       "2    [learning, full, stack, web, app, development,...\n",
       "3    [hello, teach, data, analysis, using, jupyter,...\n",
       "4    [please, come, sql, course, please, eagerly, w...\n",
       "Name: Tokenized, dtype: object"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_df['Tokenized'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1402d4d5",
   "metadata": {},
   "source": [
    "<b>POS tagging\n",
    "</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8d604c3c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T17:48:19.912431Z",
     "start_time": "2023-03-07T17:47:57.606229Z"
    }
   },
   "outputs": [],
   "source": [
    "comments_df['POS_tag'] = comments_df['Tokenized'].apply(pos_tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1661220",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0b7d1504",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T17:48:19.958954Z",
     "start_time": "2023-03-07T17:48:19.914351Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Video Number</th>\n",
       "      <th>Title</th>\n",
       "      <th>Date Published</th>\n",
       "      <th>Views</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Auther</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Clean_comment</th>\n",
       "      <th>Tokenized</th>\n",
       "      <th>POS_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>The Learning Resource That Helped People Crack...</td>\n",
       "      <td>2022-07-21</td>\n",
       "      <td>4809</td>\n",
       "      <td>180</td>\n",
       "      <td>Relax_user</td>\n",
       "      <td>Hi Mr.Patel, I am thinking about doing a maste...</td>\n",
       "      <td>hi mrpatel thinking masters data analytics how...</td>\n",
       "      <td>[hi, mrpatel, thinking, masters, data, analyti...</td>\n",
       "      <td>[(hi, JJ), (mrpatel, NN), (thinking, VBG), (ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>The Learning Resource That Helped People Crack...</td>\n",
       "      <td>2022-07-21</td>\n",
       "      <td>4809</td>\n",
       "      <td>180</td>\n",
       "      <td>Harsh Mehta</td>\n",
       "      <td>Pls come up with data analyst or data engineer...</td>\n",
       "      <td>pls come data analyst data engineer bootcamp e...</td>\n",
       "      <td>[pls, come, data, analyst, data, engineer, boo...</td>\n",
       "      <td>[(pls, NN), (come, VBN), (data, NNS), (analyst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>The Learning Resource That Helped People Crack...</td>\n",
       "      <td>2022-07-21</td>\n",
       "      <td>4809</td>\n",
       "      <td>180</td>\n",
       "      <td>Nikhil Sachdeva</td>\n",
       "      <td>I am learning the full stack web app developme...</td>\n",
       "      <td>learning full stack web app development dsa js...</td>\n",
       "      <td>[learning, full, stack, web, app, development,...</td>\n",
       "      <td>[(learning, VBG), (full, JJ), (stack, NN), (we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>The Learning Resource That Helped People Crack...</td>\n",
       "      <td>2022-07-21</td>\n",
       "      <td>4809</td>\n",
       "      <td>180</td>\n",
       "      <td>Ajinkya</td>\n",
       "      <td>Hello, Did you teach data analysis using Jupyt...</td>\n",
       "      <td>hello teach data analysis using jupyter notebo...</td>\n",
       "      <td>[hello, teach, data, analysis, using, jupyter,...</td>\n",
       "      <td>[(hello, JJ), (teach, NN), (data, NNS), (analy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>The Learning Resource That Helped People Crack...</td>\n",
       "      <td>2022-07-21</td>\n",
       "      <td>4809</td>\n",
       "      <td>180</td>\n",
       "      <td>Mohammed Shabaaz</td>\n",
       "      <td>Please come up with SQL course please?Eagerly ...</td>\n",
       "      <td>please come sql course please eagerly waiting ...</td>\n",
       "      <td>[please, come, sql, course, please, eagerly, w...</td>\n",
       "      <td>[(please, VB), (come, JJ), (sql, JJ), (course,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Video Number                                              Title  \\\n",
       "0             1  The Learning Resource That Helped People Crack...   \n",
       "1             1  The Learning Resource That Helped People Crack...   \n",
       "2             1  The Learning Resource That Helped People Crack...   \n",
       "3             1  The Learning Resource That Helped People Crack...   \n",
       "4             1  The Learning Resource That Helped People Crack...   \n",
       "\n",
       "  Date Published  Views  Likes            Auther  \\\n",
       "0     2022-07-21   4809    180        Relax_user   \n",
       "1     2022-07-21   4809    180       Harsh Mehta   \n",
       "2     2022-07-21   4809    180   Nikhil Sachdeva   \n",
       "3     2022-07-21   4809    180           Ajinkya   \n",
       "4     2022-07-21   4809    180  Mohammed Shabaaz   \n",
       "\n",
       "                                             Comment  \\\n",
       "0  Hi Mr.Patel, I am thinking about doing a maste...   \n",
       "1  Pls come up with data analyst or data engineer...   \n",
       "2  I am learning the full stack web app developme...   \n",
       "3  Hello, Did you teach data analysis using Jupyt...   \n",
       "4  Please come up with SQL course please?Eagerly ...   \n",
       "\n",
       "                                       Clean_comment  \\\n",
       "0  hi mrpatel thinking masters data analytics how...   \n",
       "1  pls come data analyst data engineer bootcamp e...   \n",
       "2  learning full stack web app development dsa js...   \n",
       "3  hello teach data analysis using jupyter notebo...   \n",
       "4  please come sql course please eagerly waiting ...   \n",
       "\n",
       "                                           Tokenized  \\\n",
       "0  [hi, mrpatel, thinking, masters, data, analyti...   \n",
       "1  [pls, come, data, analyst, data, engineer, boo...   \n",
       "2  [learning, full, stack, web, app, development,...   \n",
       "3  [hello, teach, data, analysis, using, jupyter,...   \n",
       "4  [please, come, sql, course, please, eagerly, w...   \n",
       "\n",
       "                                             POS_tag  \n",
       "0  [(hi, JJ), (mrpatel, NN), (thinking, VBG), (ma...  \n",
       "1  [(pls, NN), (come, VBN), (data, NNS), (analyst...  \n",
       "2  [(learning, VBG), (full, JJ), (stack, NN), (we...  \n",
       "3  [(hello, JJ), (teach, NN), (data, NNS), (analy...  \n",
       "4  [(please, VB), (come, JJ), (sql, JJ), (course,...  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdeee0d3",
   "metadata": {},
   "source": [
    "<b>Lemmatization\n",
    "\n",
    "Lemmatization is the process of reducing the words to its base word. For example the base word for looks, looking, looked is look.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ab5829ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T17:50:16.460326Z",
     "start_time": "2023-03-07T17:50:14.677827Z"
    }
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_md', disable=['parser', 'ner'])\n",
    "\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ']): \n",
    "    output = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(sent) \n",
    "        output.append([token.lemma_ for token in doc if token.pos_ in allowed_postags ])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9d15044d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T17:51:40.205952Z",
     "start_time": "2023-03-07T17:50:17.182117Z"
    }
   },
   "outputs": [],
   "source": [
    "lemmatized_words = lemmatization(text_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9ac835",
   "metadata": {},
   "source": [
    "#### Finding total length of lemmatized words for calculating Sentiment score.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b2a1b1fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T17:51:42.943900Z",
     "start_time": "2023-03-07T17:51:42.879506Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Video Number</th>\n",
       "      <th>Title</th>\n",
       "      <th>Date Published</th>\n",
       "      <th>Views</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Auther</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Clean_comment</th>\n",
       "      <th>Tokenized</th>\n",
       "      <th>POS_tag</th>\n",
       "      <th>Lemmatized Words</th>\n",
       "      <th>Total Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>The Learning Resource That Helped People Crack...</td>\n",
       "      <td>2022-07-21</td>\n",
       "      <td>4809</td>\n",
       "      <td>180</td>\n",
       "      <td>Relax_user</td>\n",
       "      <td>Hi Mr.Patel, I am thinking about doing a maste...</td>\n",
       "      <td>hi mrpatel thinking masters data analytics how...</td>\n",
       "      <td>[hi, mrpatel, thinking, masters, data, analyti...</td>\n",
       "      <td>[(hi, JJ), (mrpatel, NN), (thinking, VBG), (ma...</td>\n",
       "      <td>[master, datum, analytic, firm, decision, seni...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>The Learning Resource That Helped People Crack...</td>\n",
       "      <td>2022-07-21</td>\n",
       "      <td>4809</td>\n",
       "      <td>180</td>\n",
       "      <td>Harsh Mehta</td>\n",
       "      <td>Pls come up with data analyst or data engineer...</td>\n",
       "      <td>pls come data analyst data engineer bootcamp e...</td>\n",
       "      <td>[pls, come, data, analyst, data, engineer, boo...</td>\n",
       "      <td>[(pls, NN), (come, VBN), (data, NNS), (analyst...</td>\n",
       "      <td>[datum, analyst, datum, engineer, bootcamp]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>The Learning Resource That Helped People Crack...</td>\n",
       "      <td>2022-07-21</td>\n",
       "      <td>4809</td>\n",
       "      <td>180</td>\n",
       "      <td>Nikhil Sachdeva</td>\n",
       "      <td>I am learning the full stack web app developme...</td>\n",
       "      <td>learning full stack web app development dsa js...</td>\n",
       "      <td>[learning, full, stack, web, app, development,...</td>\n",
       "      <td>[(learning, VBG), (full, JJ), (stack, NN), (we...</td>\n",
       "      <td>[full, stack, web, app, development]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>The Learning Resource That Helped People Crack...</td>\n",
       "      <td>2022-07-21</td>\n",
       "      <td>4809</td>\n",
       "      <td>180</td>\n",
       "      <td>Ajinkya</td>\n",
       "      <td>Hello, Did you teach data analysis using Jupyt...</td>\n",
       "      <td>hello teach data analysis using jupyter notebo...</td>\n",
       "      <td>[hello, teach, data, analysis, using, jupyter,...</td>\n",
       "      <td>[(hello, JJ), (teach, NN), (data, NNS), (analy...</td>\n",
       "      <td>[datum, analysis, notebook]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>The Learning Resource That Helped People Crack...</td>\n",
       "      <td>2022-07-21</td>\n",
       "      <td>4809</td>\n",
       "      <td>180</td>\n",
       "      <td>Mohammed Shabaaz</td>\n",
       "      <td>Please come up with SQL course please?Eagerly ...</td>\n",
       "      <td>please come sql course please eagerly waiting ...</td>\n",
       "      <td>[please, come, sql, course, please, eagerly, w...</td>\n",
       "      <td>[(please, VB), (come, JJ), (sql, JJ), (course,...</td>\n",
       "      <td>[course, #, codebasic]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Video Number                                              Title  \\\n",
       "0             1  The Learning Resource That Helped People Crack...   \n",
       "1             1  The Learning Resource That Helped People Crack...   \n",
       "2             1  The Learning Resource That Helped People Crack...   \n",
       "3             1  The Learning Resource That Helped People Crack...   \n",
       "4             1  The Learning Resource That Helped People Crack...   \n",
       "\n",
       "  Date Published  Views  Likes            Auther  \\\n",
       "0     2022-07-21   4809    180        Relax_user   \n",
       "1     2022-07-21   4809    180       Harsh Mehta   \n",
       "2     2022-07-21   4809    180   Nikhil Sachdeva   \n",
       "3     2022-07-21   4809    180           Ajinkya   \n",
       "4     2022-07-21   4809    180  Mohammed Shabaaz   \n",
       "\n",
       "                                             Comment  \\\n",
       "0  Hi Mr.Patel, I am thinking about doing a maste...   \n",
       "1  Pls come up with data analyst or data engineer...   \n",
       "2  I am learning the full stack web app developme...   \n",
       "3  Hello, Did you teach data analysis using Jupyt...   \n",
       "4  Please come up with SQL course please?Eagerly ...   \n",
       "\n",
       "                                       Clean_comment  \\\n",
       "0  hi mrpatel thinking masters data analytics how...   \n",
       "1  pls come data analyst data engineer bootcamp e...   \n",
       "2  learning full stack web app development dsa js...   \n",
       "3  hello teach data analysis using jupyter notebo...   \n",
       "4  please come sql course please eagerly waiting ...   \n",
       "\n",
       "                                           Tokenized  \\\n",
       "0  [hi, mrpatel, thinking, masters, data, analyti...   \n",
       "1  [pls, come, data, analyst, data, engineer, boo...   \n",
       "2  [learning, full, stack, web, app, development,...   \n",
       "3  [hello, teach, data, analysis, using, jupyter,...   \n",
       "4  [please, come, sql, course, please, eagerly, w...   \n",
       "\n",
       "                                             POS_tag  \\\n",
       "0  [(hi, JJ), (mrpatel, NN), (thinking, VBG), (ma...   \n",
       "1  [(pls, NN), (come, VBN), (data, NNS), (analyst...   \n",
       "2  [(learning, VBG), (full, JJ), (stack, NN), (we...   \n",
       "3  [(hello, JJ), (teach, NN), (data, NNS), (analy...   \n",
       "4  [(please, VB), (come, JJ), (sql, JJ), (course,...   \n",
       "\n",
       "                                    Lemmatized Words  Total Length  \n",
       "0  [master, datum, analytic, firm, decision, seni...             9  \n",
       "1        [datum, analyst, datum, engineer, bootcamp]             5  \n",
       "2               [full, stack, web, app, development]             5  \n",
       "3                        [datum, analysis, notebook]             3  \n",
       "4                             [course, #, codebasic]             3  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_df['Lemmatized Words'] = [i for i in lemmatized_words]\n",
    "comments_df['Total Length'] = [len(i) for i in lemmatized_words]\n",
    "comments_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d29bf01f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T17:52:03.874371Z",
     "start_time": "2023-03-07T17:52:03.861402Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: \n",
      "Sir you could include python intermediate and python advance as well in the course\n",
      "\n",
      "After: \n",
      "['intermediate', 'advance', 'course']\n"
     ]
    }
   ],
   "source": [
    "index = 88\n",
    "\n",
    "print(f'Before: \\n{text_list[index]}')\n",
    "\n",
    "# text_list_lemma = comments_df['Comment'].tolist()\n",
    "print(f'\\nAfter: \\n{lemmatized_words[index]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "dab180b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T17:52:10.434919Z",
     "start_time": "2023-03-07T17:52:10.423508Z"
    }
   },
   "outputs": [],
   "source": [
    "file1 = open('positive-words.txt', 'r')\n",
    "pos_words= file1.read().split()\n",
    "\n",
    "file2 = open('negative-words.txt', 'r')\n",
    "neg_words= file2.read().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "317b2975",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T17:55:05.788711Z",
     "start_time": "2023-03-07T17:55:05.780477Z"
    }
   },
   "outputs": [],
   "source": [
    "def count_pos(text):\n",
    "    \n",
    "    count = 0\n",
    "    for i in text:\n",
    "        if i in pos_words:\n",
    "            count += 1\n",
    "            \n",
    "    return count\n",
    "\n",
    "def count_neg(text):\n",
    "    \n",
    "    count = 0\n",
    "    for i in text:\n",
    "        if i in neg_words:\n",
    "            count += 1\n",
    "            \n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c2eb36c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T17:56:53.451794Z",
     "start_time": "2023-03-07T17:56:53.369832Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Video Number</th>\n",
       "      <th>Title</th>\n",
       "      <th>Date Published</th>\n",
       "      <th>Views</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Auther</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Clean_comment</th>\n",
       "      <th>Tokenized</th>\n",
       "      <th>POS_tag</th>\n",
       "      <th>Lemmatized Words</th>\n",
       "      <th>Total Length</th>\n",
       "      <th>Positive count</th>\n",
       "      <th>Negative count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>The Learning Resource That Helped People Crack...</td>\n",
       "      <td>2022-07-21</td>\n",
       "      <td>4809</td>\n",
       "      <td>180</td>\n",
       "      <td>Relax_user</td>\n",
       "      <td>Hi Mr.Patel, I am thinking about doing a maste...</td>\n",
       "      <td>hi mrpatel thinking masters data analytics how...</td>\n",
       "      <td>[hi, mrpatel, thinking, masters, data, analyti...</td>\n",
       "      <td>[(hi, JJ), (mrpatel, NN), (thinking, VBG), (ma...</td>\n",
       "      <td>[master, datum, analytic, firm, decision, seni...</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>The Learning Resource That Helped People Crack...</td>\n",
       "      <td>2022-07-21</td>\n",
       "      <td>4809</td>\n",
       "      <td>180</td>\n",
       "      <td>Harsh Mehta</td>\n",
       "      <td>Pls come up with data analyst or data engineer...</td>\n",
       "      <td>pls come data analyst data engineer bootcamp e...</td>\n",
       "      <td>[pls, come, data, analyst, data, engineer, boo...</td>\n",
       "      <td>[(pls, NN), (come, VBN), (data, NNS), (analyst...</td>\n",
       "      <td>[datum, analyst, datum, engineer, bootcamp]</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>The Learning Resource That Helped People Crack...</td>\n",
       "      <td>2022-07-21</td>\n",
       "      <td>4809</td>\n",
       "      <td>180</td>\n",
       "      <td>Nikhil Sachdeva</td>\n",
       "      <td>I am learning the full stack web app developme...</td>\n",
       "      <td>learning full stack web app development dsa js...</td>\n",
       "      <td>[learning, full, stack, web, app, development,...</td>\n",
       "      <td>[(learning, VBG), (full, JJ), (stack, NN), (we...</td>\n",
       "      <td>[full, stack, web, app, development]</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>The Learning Resource That Helped People Crack...</td>\n",
       "      <td>2022-07-21</td>\n",
       "      <td>4809</td>\n",
       "      <td>180</td>\n",
       "      <td>Ajinkya</td>\n",
       "      <td>Hello, Did you teach data analysis using Jupyt...</td>\n",
       "      <td>hello teach data analysis using jupyter notebo...</td>\n",
       "      <td>[hello, teach, data, analysis, using, jupyter,...</td>\n",
       "      <td>[(hello, JJ), (teach, NN), (data, NNS), (analy...</td>\n",
       "      <td>[datum, analysis, notebook]</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>The Learning Resource That Helped People Crack...</td>\n",
       "      <td>2022-07-21</td>\n",
       "      <td>4809</td>\n",
       "      <td>180</td>\n",
       "      <td>Mohammed Shabaaz</td>\n",
       "      <td>Please come up with SQL course please?Eagerly ...</td>\n",
       "      <td>please come sql course please eagerly waiting ...</td>\n",
       "      <td>[please, come, sql, course, please, eagerly, w...</td>\n",
       "      <td>[(please, VB), (come, JJ), (sql, JJ), (course,...</td>\n",
       "      <td>[course, #, codebasic]</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>The Learning Resource That Helped People Crack...</td>\n",
       "      <td>2022-07-21</td>\n",
       "      <td>4809</td>\n",
       "      <td>180</td>\n",
       "      <td>Ajinkya</td>\n",
       "      <td>But your DSA is incomplete, please complete it...</td>\n",
       "      <td>dsa incomplete please complete first dp etc</td>\n",
       "      <td>[dsa, incomplete, please, complete, first, dp,...</td>\n",
       "      <td>[(dsa, NN), (incomplete, JJ), (please, NN), (c...</td>\n",
       "      <td>[incomplete, dp]</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>The Learning Resource That Helped People Crack...</td>\n",
       "      <td>2022-07-21</td>\n",
       "      <td>4809</td>\n",
       "      <td>180</td>\n",
       "      <td>Felix Gondwe</td>\n",
       "      <td>I love love your tutorials! Where's the merch?...</td>\n",
       "      <td>love love tutorials wheres merch coz fan need ...</td>\n",
       "      <td>[love, love, tutorials, wheres, merch, coz, fa...</td>\n",
       "      <td>[(love, VB), (love, NN), (tutorials, NNS), (wh...</td>\n",
       "      <td>[tutorial, merch, fan, codebasic, shirt]</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>The Learning Resource That Helped People Crack...</td>\n",
       "      <td>2022-07-21</td>\n",
       "      <td>4809</td>\n",
       "      <td>180</td>\n",
       "      <td>김우성</td>\n",
       "      <td>Hi, Mr Patel \\nCan i ask you to treat about gr...</td>\n",
       "      <td>hi mr patel ask treat growth hacking skills wa...</td>\n",
       "      <td>[hi, mr, patel, ask, treat, growth, hacking, s...</td>\n",
       "      <td>[(hi, NN), (mr, NN), (patel, NN), (ask, NN), (...</td>\n",
       "      <td>[growth, hacking, skill, information]</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>The Learning Resource That Helped People Crack...</td>\n",
       "      <td>2022-07-21</td>\n",
       "      <td>4809</td>\n",
       "      <td>180</td>\n",
       "      <td>Praphul Shaw</td>\n",
       "      <td>How to do project pls help</td>\n",
       "      <td>project pls help</td>\n",
       "      <td>[project, pls, help]</td>\n",
       "      <td>[(project, NN), (pls, NN), (help, NN)]</td>\n",
       "      <td>[project]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>The Learning Resource That Helped People Crack...</td>\n",
       "      <td>2022-07-21</td>\n",
       "      <td>4809</td>\n",
       "      <td>180</td>\n",
       "      <td>Atharv Kumar</td>\n",
       "      <td>While True:\\n    print('Nice :×D')</td>\n",
       "      <td>true print nice</td>\n",
       "      <td>[true, print, nice]</td>\n",
       "      <td>[(true, JJ), (print, NN), (nice, NN)]</td>\n",
       "      <td>[true]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Video Number                                              Title  \\\n",
       "0             1  The Learning Resource That Helped People Crack...   \n",
       "1             1  The Learning Resource That Helped People Crack...   \n",
       "2             1  The Learning Resource That Helped People Crack...   \n",
       "3             1  The Learning Resource That Helped People Crack...   \n",
       "4             1  The Learning Resource That Helped People Crack...   \n",
       "5             1  The Learning Resource That Helped People Crack...   \n",
       "6             1  The Learning Resource That Helped People Crack...   \n",
       "7             1  The Learning Resource That Helped People Crack...   \n",
       "8             1  The Learning Resource That Helped People Crack...   \n",
       "9             1  The Learning Resource That Helped People Crack...   \n",
       "\n",
       "  Date Published  Views  Likes            Auther  \\\n",
       "0     2022-07-21   4809    180        Relax_user   \n",
       "1     2022-07-21   4809    180       Harsh Mehta   \n",
       "2     2022-07-21   4809    180   Nikhil Sachdeva   \n",
       "3     2022-07-21   4809    180           Ajinkya   \n",
       "4     2022-07-21   4809    180  Mohammed Shabaaz   \n",
       "5     2022-07-21   4809    180           Ajinkya   \n",
       "6     2022-07-21   4809    180      Felix Gondwe   \n",
       "7     2022-07-21   4809    180               김우성   \n",
       "8     2022-07-21   4809    180      Praphul Shaw   \n",
       "9     2022-07-21   4809    180      Atharv Kumar   \n",
       "\n",
       "                                             Comment  \\\n",
       "0  Hi Mr.Patel, I am thinking about doing a maste...   \n",
       "1  Pls come up with data analyst or data engineer...   \n",
       "2  I am learning the full stack web app developme...   \n",
       "3  Hello, Did you teach data analysis using Jupyt...   \n",
       "4  Please come up with SQL course please?Eagerly ...   \n",
       "5  But your DSA is incomplete, please complete it...   \n",
       "6  I love love your tutorials! Where's the merch?...   \n",
       "7  Hi, Mr Patel \\nCan i ask you to treat about gr...   \n",
       "8                         How to do project pls help   \n",
       "9                 While True:\\n    print('Nice :×D')   \n",
       "\n",
       "                                       Clean_comment  \\\n",
       "0  hi mrpatel thinking masters data analytics how...   \n",
       "1  pls come data analyst data engineer bootcamp e...   \n",
       "2  learning full stack web app development dsa js...   \n",
       "3  hello teach data analysis using jupyter notebo...   \n",
       "4  please come sql course please eagerly waiting ...   \n",
       "5       dsa incomplete please complete first dp etc    \n",
       "6  love love tutorials wheres merch coz fan need ...   \n",
       "7  hi mr patel ask treat growth hacking skills wa...   \n",
       "8                                  project pls help    \n",
       "9                                  true print nice     \n",
       "\n",
       "                                           Tokenized  \\\n",
       "0  [hi, mrpatel, thinking, masters, data, analyti...   \n",
       "1  [pls, come, data, analyst, data, engineer, boo...   \n",
       "2  [learning, full, stack, web, app, development,...   \n",
       "3  [hello, teach, data, analysis, using, jupyter,...   \n",
       "4  [please, come, sql, course, please, eagerly, w...   \n",
       "5  [dsa, incomplete, please, complete, first, dp,...   \n",
       "6  [love, love, tutorials, wheres, merch, coz, fa...   \n",
       "7  [hi, mr, patel, ask, treat, growth, hacking, s...   \n",
       "8                               [project, pls, help]   \n",
       "9                                [true, print, nice]   \n",
       "\n",
       "                                             POS_tag  \\\n",
       "0  [(hi, JJ), (mrpatel, NN), (thinking, VBG), (ma...   \n",
       "1  [(pls, NN), (come, VBN), (data, NNS), (analyst...   \n",
       "2  [(learning, VBG), (full, JJ), (stack, NN), (we...   \n",
       "3  [(hello, JJ), (teach, NN), (data, NNS), (analy...   \n",
       "4  [(please, VB), (come, JJ), (sql, JJ), (course,...   \n",
       "5  [(dsa, NN), (incomplete, JJ), (please, NN), (c...   \n",
       "6  [(love, VB), (love, NN), (tutorials, NNS), (wh...   \n",
       "7  [(hi, NN), (mr, NN), (patel, NN), (ask, NN), (...   \n",
       "8             [(project, NN), (pls, NN), (help, NN)]   \n",
       "9              [(true, JJ), (print, NN), (nice, NN)]   \n",
       "\n",
       "                                    Lemmatized Words  Total Length  \\\n",
       "0  [master, datum, analytic, firm, decision, seni...             9   \n",
       "1        [datum, analyst, datum, engineer, bootcamp]             5   \n",
       "2               [full, stack, web, app, development]             5   \n",
       "3                        [datum, analysis, notebook]             3   \n",
       "4                             [course, #, codebasic]             3   \n",
       "5                                   [incomplete, dp]             2   \n",
       "6           [tutorial, merch, fan, codebasic, shirt]             5   \n",
       "7              [growth, hacking, skill, information]             4   \n",
       "8                                          [project]             1   \n",
       "9                                             [true]             1   \n",
       "\n",
       "   Positive count  Negative count  \n",
       "0               0               0  \n",
       "1               0               0  \n",
       "2               0               0  \n",
       "3               0               0  \n",
       "4               0               0  \n",
       "5               0               0  \n",
       "6               0               0  \n",
       "7               0               0  \n",
       "8               0               0  \n",
       "9               0               0  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_df['Positive count'] = comments_df['Lemmatized Words'].apply(count_pos)\n",
    "comments_df['Negative count'] = comments_df['Lemmatized Words'].apply(count_neg)\n",
    "comments_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1f4726c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T17:57:48.531644Z",
     "start_time": "2023-03-07T17:57:48.481324Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Video Number</th>\n",
       "      <th>Title</th>\n",
       "      <th>Date Published</th>\n",
       "      <th>Views</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Auther</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Clean_comment</th>\n",
       "      <th>Tokenized</th>\n",
       "      <th>POS_tag</th>\n",
       "      <th>Lemmatized Words</th>\n",
       "      <th>Total Length</th>\n",
       "      <th>Positive count</th>\n",
       "      <th>Negative count</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>The Learning Resource That Helped People Crack...</td>\n",
       "      <td>2022-07-21</td>\n",
       "      <td>4809</td>\n",
       "      <td>180</td>\n",
       "      <td>Relax_user</td>\n",
       "      <td>Hi Mr.Patel, I am thinking about doing a maste...</td>\n",
       "      <td>hi mrpatel thinking masters data analytics how...</td>\n",
       "      <td>[hi, mrpatel, thinking, masters, data, analyti...</td>\n",
       "      <td>[(hi, JJ), (mrpatel, NN), (thinking, VBG), (ma...</td>\n",
       "      <td>[master, datum, analytic, firm, decision, seni...</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>The Learning Resource That Helped People Crack...</td>\n",
       "      <td>2022-07-21</td>\n",
       "      <td>4809</td>\n",
       "      <td>180</td>\n",
       "      <td>Harsh Mehta</td>\n",
       "      <td>Pls come up with data analyst or data engineer...</td>\n",
       "      <td>pls come data analyst data engineer bootcamp e...</td>\n",
       "      <td>[pls, come, data, analyst, data, engineer, boo...</td>\n",
       "      <td>[(pls, NN), (come, VBN), (data, NNS), (analyst...</td>\n",
       "      <td>[datum, analyst, datum, engineer, bootcamp]</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>The Learning Resource That Helped People Crack...</td>\n",
       "      <td>2022-07-21</td>\n",
       "      <td>4809</td>\n",
       "      <td>180</td>\n",
       "      <td>Nikhil Sachdeva</td>\n",
       "      <td>I am learning the full stack web app developme...</td>\n",
       "      <td>learning full stack web app development dsa js...</td>\n",
       "      <td>[learning, full, stack, web, app, development,...</td>\n",
       "      <td>[(learning, VBG), (full, JJ), (stack, NN), (we...</td>\n",
       "      <td>[full, stack, web, app, development]</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>The Learning Resource That Helped People Crack...</td>\n",
       "      <td>2022-07-21</td>\n",
       "      <td>4809</td>\n",
       "      <td>180</td>\n",
       "      <td>Ajinkya</td>\n",
       "      <td>Hello, Did you teach data analysis using Jupyt...</td>\n",
       "      <td>hello teach data analysis using jupyter notebo...</td>\n",
       "      <td>[hello, teach, data, analysis, using, jupyter,...</td>\n",
       "      <td>[(hello, JJ), (teach, NN), (data, NNS), (analy...</td>\n",
       "      <td>[datum, analysis, notebook]</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>The Learning Resource That Helped People Crack...</td>\n",
       "      <td>2022-07-21</td>\n",
       "      <td>4809</td>\n",
       "      <td>180</td>\n",
       "      <td>Mohammed Shabaaz</td>\n",
       "      <td>Please come up with SQL course please?Eagerly ...</td>\n",
       "      <td>please come sql course please eagerly waiting ...</td>\n",
       "      <td>[please, come, sql, course, please, eagerly, w...</td>\n",
       "      <td>[(please, VB), (come, JJ), (sql, JJ), (course,...</td>\n",
       "      <td>[course, #, codebasic]</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Video Number                                              Title  \\\n",
       "0             1  The Learning Resource That Helped People Crack...   \n",
       "1             1  The Learning Resource That Helped People Crack...   \n",
       "2             1  The Learning Resource That Helped People Crack...   \n",
       "3             1  The Learning Resource That Helped People Crack...   \n",
       "4             1  The Learning Resource That Helped People Crack...   \n",
       "\n",
       "  Date Published  Views  Likes            Auther  \\\n",
       "0     2022-07-21   4809    180        Relax_user   \n",
       "1     2022-07-21   4809    180       Harsh Mehta   \n",
       "2     2022-07-21   4809    180   Nikhil Sachdeva   \n",
       "3     2022-07-21   4809    180           Ajinkya   \n",
       "4     2022-07-21   4809    180  Mohammed Shabaaz   \n",
       "\n",
       "                                             Comment  \\\n",
       "0  Hi Mr.Patel, I am thinking about doing a maste...   \n",
       "1  Pls come up with data analyst or data engineer...   \n",
       "2  I am learning the full stack web app developme...   \n",
       "3  Hello, Did you teach data analysis using Jupyt...   \n",
       "4  Please come up with SQL course please?Eagerly ...   \n",
       "\n",
       "                                       Clean_comment  \\\n",
       "0  hi mrpatel thinking masters data analytics how...   \n",
       "1  pls come data analyst data engineer bootcamp e...   \n",
       "2  learning full stack web app development dsa js...   \n",
       "3  hello teach data analysis using jupyter notebo...   \n",
       "4  please come sql course please eagerly waiting ...   \n",
       "\n",
       "                                           Tokenized  \\\n",
       "0  [hi, mrpatel, thinking, masters, data, analyti...   \n",
       "1  [pls, come, data, analyst, data, engineer, boo...   \n",
       "2  [learning, full, stack, web, app, development,...   \n",
       "3  [hello, teach, data, analysis, using, jupyter,...   \n",
       "4  [please, come, sql, course, please, eagerly, w...   \n",
       "\n",
       "                                             POS_tag  \\\n",
       "0  [(hi, JJ), (mrpatel, NN), (thinking, VBG), (ma...   \n",
       "1  [(pls, NN), (come, VBN), (data, NNS), (analyst...   \n",
       "2  [(learning, VBG), (full, JJ), (stack, NN), (we...   \n",
       "3  [(hello, JJ), (teach, NN), (data, NNS), (analy...   \n",
       "4  [(please, VB), (come, JJ), (sql, JJ), (course,...   \n",
       "\n",
       "                                    Lemmatized Words  Total Length  \\\n",
       "0  [master, datum, analytic, firm, decision, seni...             9   \n",
       "1        [datum, analyst, datum, engineer, bootcamp]             5   \n",
       "2               [full, stack, web, app, development]             5   \n",
       "3                        [datum, analysis, notebook]             3   \n",
       "4                             [course, #, codebasic]             3   \n",
       "\n",
       "   Positive count  Negative count  Sentiment  \n",
       "0               0               0        0.0  \n",
       "1               0               0        0.0  \n",
       "2               0               0        0.0  \n",
       "3               0               0        0.0  \n",
       "4               0               0        0.0  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_df['Sentiment'] = round(((comments_df['Positive count'] - comments_df['Negative count']) / comments_df['Total Length']), 2)\n",
    "comments_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
